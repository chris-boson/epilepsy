
\section{Generative Models and Large Language Models}

A recent trend, one that has gained notoriety in circles far outside of machine learning, is the usage of generative AI
and large language models \textit{LLMs} for both ML and non-ML applications. These are largely unsupervised, or sometimes
semi-supervised, algorithms that generate content from analyzing existing content. This content is often text, but in recent
multi-modal models such as OpenAI's GPT-4, can be other modalities such as images as well, or  even a combination thereof.

Large Language Models have gained notoriety specifically because they have arguably reached human-level performance, and according
to some even passed it, on this task of generating text from a prompt (often called context). The word "large" here is an understatement,
as these models have billions upon billions of parameters, and rely on neural architectures that stack transformers and other large
computation operations across many GPU's.

What makes these newer language models such as OpenAI's \textit{ChatGPT}, Meta AI's \textit{Llama}, or Google's \textit{Bard} so special
is their ability to generate high-quality content at scale without a loss in accuracy. In the case of ChatGPT, a fine-tuning process with
human labelers called Reinforcement Learning With Human Feedback \textit{RLHF} targeted iteratively improving the model by specifically
rewarding high-quality content and penalizing toxic feedback. Because these models are trained on text across the internet, which
unsurprisingly included troves of nonsense and hate speech, these models must be pushed toward not pure unsupervised generation of content,
as this can be dangerous.

\subsection{LLMs and Epilepsy}

Consider the following example from OpenAI's ChatGPT (March 14, 2023 version)

\begin{displayquote}
  Prompt: "A patient with an epilepsy history is taking \
  Phenytoin, and their morning lab work shows their Phenytoin\
  level is 7 mcg/mL. What does this mean?"
\end{displayquote}

\begin{displayquote}
  ChatGPT response: "Phenytoin is an antiepileptic drug used to control seizures. The therapeutic range for Phenytoin is usually between 10 and 20 mcg/mL. If a patient's Phenytoin level is 7 mcg/mL, it is considered to be below the therapeutic range.

  A low Phenytoin level could indicate that the patient may be at risk of experiencing seizures, as the drug may not be providing adequate seizure control. Additionally, a low level may suggest that the patient is not taking the medication as prescribed or is not absorbing the drug adequately.
  
  Therefore, it is essential to inform the healthcare provider of the patient's low Phenytoin level, and follow their instructions regarding further action. The healthcare provider may order additional testing or adjust the patient's medication dose to achieve the optimal therapeutic range.
  
  It is also essential to monitor the patient's symptoms and seizure activity closely and report any changes or concerns to the healthcare provider. It is crucial to adhere to the healthcare provider's instructions and medication administration guidelines to ensure that the patient's seizures are adequately controlled.
\end{displayquote}

Considering this is a generated response, it goes without saying that this is a promising step toward advancements in tools
in the medical field. The models are so large that they can fit in a rich back-and-forth discussion, without a sacrifice
in depth.

\begin{python}
    prompt_1 = "In such cases if a multi focal seizure is present, when would nerve stimulation be preferred over surgery"
  
    #... send to ChatGPT over OpenAI Api ...
  
    response = COPY THIS RESPONSE IN
  \end{python}

\subsection{Prompt Design, Context, and Fine-Tuning}

\subsection{Revisiting Our Tasks}

\subsection{Notes on The Future of Generative AI in Medicine}
