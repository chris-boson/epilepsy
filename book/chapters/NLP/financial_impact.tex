\section{Full Walkthrough - Brain Surgery and Financial Impact of Epilepsy}

In this section we will demonstrate how the techniques discussed above can be applied to a practical example within the field of Epilepsy.
Modern NLP techniques are a powerful tool to analyze large amounts of unstructred or semi structured text data, and we can employ them to develop a coding scheme and significantly reduce the time required to apply it to new data.

We are providing self contained code examples in the acompanying GitHub repository\footnote{https://github.com/chris-boson/epilepsy} that makes use of a general purpose NLP library\footnote{https://github.com/robmsylvester/sheepy} we have developed to make current industry standard tools and libraries more accessible to researchers and practitioners.


\subsection{Data Analysis}
For this section we started out with fairly small dataset ($\sim150$ rows) derived from survey responses regarding  impact and treatment of epilepsy\footnote{Seizure Tracker}:
\begin{displayquote}
    Do you have any comments on the financial impact of epilepsy?

    Do you have any comments about brain surgery in general?
\end{displayquote}
This dataset is small enough to manually inspect, but we the techniques discussed here scale well beyond.
\subsubsection{Embeddings}

\subsubsection{Dimensionality Reduction and Clustering}
\subsubsection{Cluster Labeling}
\subsubsection{Annotation}
We can use the cluster labels as a starting point to decide on a coding scheme. For the general comments we decided on the following labels:
\begin{displayquote}
    \texttt{"Not eligible"},
    \texttt{"Last resort"},
    \texttt{"Would never do it"},

    \texttt{"Considering it"},
    \texttt{"Was Unsuccessful"},
    \texttt{"Was partially successful"},

    \texttt{"Was successful"},
    \texttt{"Side effects"},
    \texttt{"Risk"},

    \texttt{"Too expensive"},
    \texttt{"Complications"},
    \texttt{"Unknown outcome"},

    \texttt{"Unnecessary"},
    \texttt{"Cannot find origin"}
\end{displayquote}
We treat this as a so called multilabel classification problem, where a given sample can have multiple true labels simultaneously (i.e. a surgery can be successful and have side effects).

The labeling scheme should cover all the aspects of the data of interest.
It also needs to be unambiguous, meaning that two experts independently generating the annotations should largely agree on what the correct labels are for each sample.
If human experts cannot agree, the model will most likely perform poorly as well, as it gets inconsistent signals during training.
If this is the case, the coding scheme or annotation instructions should be revised.
We will discuss in Section \ref{metrics_and_sanity_checking} how to go about analyzing model performance and uncover issues in data and annotations.



%     - SHAP
%     - Analyze mistakes
%     - Inference
