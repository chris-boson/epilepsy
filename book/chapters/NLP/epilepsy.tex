\section{NLP Tasks in Epilepsy}

Now that we have an understanding of some of the basics of computational representations of language data, let us take a look at some of the modern use cases for NLP in industry, catered toward epileptologists and other medical practitioners.

\subsection{Unstructured Text - Retrospective Research}
Within the medical field, there are many sources of unstructured text that are primarily aimed as a either a communication channel between specialists, or a way for patients to pass information that isn't captured in a structured format.
Clinical Notes, Progress Notes, Operative Notes, Discharge Summaries, Pathology Reports, Surgery Reports; all of these sources carry information, but traditionally require experts in the field to extract it.
If we can teach systems to read through this unstructured text and perform respectably close to these experts, we can perform large-scale clinical retrospective research much faster and at a much lower cost.

Because these pre-trained language models can draw upon information from so many domains and have a sound understanding of language, they need relatively few
labeled examples to begin to perform tasks such as classifying text. All they have to learn is the task at hand, not the nuances of languages.
If a team of experts is able to identify a set of labels in which they are interested, they can label this data in a single shot. The next step is to fine-tune a pre-trained language model, often by just attaching a logistic regression layer to the outputs of the language model,
to recognize each of these labels.

Instead of having to wait for, not to mention pay for, experts to do large-scale retrospective research, fine-tuned pre-trained language models can perform admirably on text classification with, in many cases, only a few hundred labeled examples.
The trained model can then read through and extract targeted text much faster and much cheaper.
Studies have already been done applying this strategy, using three pre-trained neural language models, \texttt{Bio\textunderscore ClinicalBERT}, to extract
seizure frequency from epilepsy clinical notes.\cite{10.1093/jamia/ocac018}

\subsection{Unstructured Text - Quality of Life}
When treating patients with epilepsy, often our principal aim is to target improving quality of life. Seizure frequency is a numeric represenation that has a measurement
that is well-understood and directly impacts quality of life. However, many measurements of quality of life come directly from patient surveys and other more subjective
metrics that can be more difficult to interpret at scale. While often these surveys call for responses on numeric scales, many offer unstructured text as a method for
patients to freely communicate other information relevant to quality of life, or further explain their responses. This information is of exceptional importance, but it
can be difficult to parse through it at scale without modern natural language processing techniques.

Sentiment analysis, the task of extracting and studying subjective sentiment in text and speech data, is yet another field of NLP that has greatly benefited from the
widespread adoption of transformer architectures, particularly in specialized domains. Freeform responses that can be evaluated as positive or negative, or sometimes into more
granular sentiments, can be learned with machine learning methods. It's worth noting that naive methods on sentiment tend to capture some cases well. The words love and hate are
strong signals, but even their simple negation becomes a diluted signal with possible interpretations of sarcasm that become subjective. Add in the many colorful ways that people
write, and we start to see why rules-based text-mining systems for sentiment are so difficult.

Sentiment analysis models using transformer architectures such as RoBERTa aim to project the large-dimensional output vector of the text, and project this semantic representation
into a basic sentiment of two class, positive or negative. Very often a third class is used to represent neutral sentiment. This method should be used when analyzing free-form responses
in patient surveys using NLP models trained on sentiment. While a model trained on medical data is ideal, it's quite impressive how well a model trained on movie reviews will transfer
over to other sentiment tasks.

The same methods for analyzing basic sentiment can be used to label tones, more granular emotional classifications, or other task-specific points of interest. Similar to
the case with the retrospective research in section 1.2.1, it is important to have the survey designers, and/or other domain experts, label these targeted semantic
expressions of their patients. Once a model is trained with a set of positive examples of these targets, it can be used on any text response.

The datasets provided by SeizureTracker, as part of their It's Not Just Seizures (INJS) initiative, provides an excellent example of unstructured text responses being
used as a guide to a suggested set of useful labels that can be learned with NLP techniques. This is outlined in section 1.5
\subsection{Text Preprocessing and Tokenization}

Placeholder.

\subsection{Named Entity Recognition and PII}

Named Entity Recognition (NER) is a subtask of information extraction that classifies unstructured text into personal names, locations, time indications, organizations, and other tags.
NER is an important problem in medicine, if nothing else to provide an ability to mask out Personally-Identifiable Information.
If a model, probably a transformer architecture in practice, is able to identify text as a first name, a home address, or a credit card number, then we can anonymize this information to mask information that is PII-specific.

It should be noted that, although some of this text is easy to catch with rule-based approaches and regular expressions, such as a credit card number, other information requires contextual understanding and an ML solution
to achieve the necessary performance.

Spacy, NLTK, and Stanford NLP all provide out-of-the-box NER models that perform well on unstructured text. Let's look at a Spacy example in practice.

\begin{python}
  # Example 4 - Simple PII Anonymizer

  import spacy

  sample = "The patient, John Smith, began feeling symptoms at his home in Seattle, and was taken to Virginia Mason Medical Center for treatment"
  nlp = spacy.load("en_core_web_md")

  doc = nlp(sample)

  for word in doc.ents:
      sample = sample.replace(word.text, word.label_)

  print(sample)

  #The patient, PERSON, began feeling symptoms at his home in GPE, and was taken to ORG for treatment

\end{python}

\subsection{Mining Unstructured Text and Clinical Documentation}

This is placeholder text. Talk about clinical documentation and EHR notes, and other forms of unstructred text, being used for downstream classification tasks.
Then, give some examples of them, and what these people did, and possibly how transformers could probably improve this work greatly.

\subsection{Clinical Trial Matching and Eligibility Prescreening}

This is a placeholder text. https://www.nature.com/articles/d41586-019-02871-3

\subsection{Surgical Candidacy}

This is placeholder text

\subsection{Avoiding Epilepsy Misdiagnosis}

This is placeholder text. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4419916/
