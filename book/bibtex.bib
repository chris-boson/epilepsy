@article{DBLP:journals/corr/abs-1901-08746,
  author     = {Jinhyuk Lee and
                Wonjin Yoon and
                Sungdong Kim and
                Donghyeon Kim and
                Sunkyu Kim and
                Chan Ho So and
                Jaewoo Kang},
  title      = {BioBERT: a pre-trained biomedical language representation model for
                biomedical text mining},
  journal    = {CoRR},
  volume     = {abs/1901.08746},
  year       = {2019},
  url        = {http://arxiv.org/abs/1901.08746},
  eprinttype = {arXiv},
  eprint     = {1901.08746},
  timestamp  = {Sat, 23 Jan 2021 01:13:47 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1901-08746.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{10.1093/jamia/ocac018,
  author   = {Xie, Kevin and Gallagher, Ryan S and Conrad, Erin C and Garrick, Chadric O and Baldassano, Steven N and Bernabei, John M and Galer, Peter D and Ghosn, Nina J and Greenblatt, Adam S and Jennings, Tara and Kornspun, Alana and Kulick-Soper, Catherine V and Panchal, Jal M and Pattnaik, Akash R and Scheid, Brittany H and Wei, Danmeng and Weitzman, Micah and Muthukrishnan, Ramya and Kim, Joongwon and Litt, Brian and Ellis, Colin A and Roth, Dan},
  title    = {{Extracting seizure frequency from epilepsy clinic notes: a machine reading approach to natural language processing}},
  journal  = {Journal of the American Medical Informatics Association},
  volume   = {29},
  number   = {5},
  pages    = {873-881},
  year     = {2022},
  month    = {02},
  abstract = {{Seizure frequency and seizure freedom are among the most important outcome measures for patients with epilepsy. In this study, we aimed to automatically extract this clinical information from unstructured text in clinical notes. If successful, this could improve clinical decision-making in epilepsy patients and allow for rapid, large-scale retrospective research.We developed a finetuning pipeline for pretrained neural models to classify patients as being seizure-free and to extract text containing their seizure frequency and date of last seizure from clinical notes. We annotated 1000 notes for use as training and testing data and determined how well 3 pretrained neural models, BERT, RoBERTa, and Bio\_ClinicalBERT, could identify and extract the desired information after finetuning.The finetuned models (BERTFT, Bio\_ClinicalBERTFT, and RoBERTaFT) achieved near-human performance when classifying patients as seizure free, with BERTFT and Bio\_ClinicalBERTFT achieving accuracy scores over 80\\%. All 3 models also achieved human performance when extracting seizure frequency and date of last seizure, with overall F1 scores over 0.80. The best combination of models was Bio\_ClinicalBERTFT for classification, and RoBERTaFT for text extraction. Most of the gains in performance due to finetuning required roughly 70 annotated notes.Our novel machine reading approach to extracting important clinical outcomes performed at or near human performance on several tasks. This approach opens new possibilities to support clinical practice and conduct large-scale retrospective clinical research. Future studies can use our finetuning pipeline with minimal training annotations to answer new clinical questions.}},
  issn     = {1527-974X},
  doi      = {10.1093/jamia/ocac018},
  url      = {https://doi.org/10.1093/jamia/ocac018},
  eprint   = {https://academic.oup.com/jamia/article-pdf/29/5/873/43372456/ocac018.pdf}
}

@misc{https://doi.org/10.48550/arxiv.1706.03762,
  doi       = {10.48550/ARXIV.1706.03762},
  url       = {https://arxiv.org/abs/1706.03762},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Attention Is All You Need},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

 @misc{illustratedtransformer,
  title   = {The illustrated transformer},
  url     = {https://jalammar.github.io/illustrated-transformer/},
  journal = {The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.},
  author  = {Alammar, Jay}
}

@misc{https://doi.org/10.48550/arxiv.1810.04805,
  doi       = {10.48550/ARXIV.1810.04805},
  url       = {https://arxiv.org/abs/1810.04805},
  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1904.03323,
  doi       = {10.48550/ARXIV.1904.03323},
  url       = {https://arxiv.org/abs/1904.03323},
  author    = {Alsentzer, Emily and Murphy, John R. and Boag, Willie and Weng, Wei-Hung and Jin, Di and Naumann, Tristan and McDermott, Matthew B. A.},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Publicly Available Clinical BERT Embeddings},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1301.3781,
  doi       = {10.48550/ARXIV.1301.3781},
  url       = {https://arxiv.org/abs/1301.3781},
  author    = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Efficient Estimation of Word Representations in Vector Space},
  publisher = {arXiv},
  year      = {2013},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{shannon48,
  author  = {Shannon, C. E.},
  journal = {The Bell System Technical Journal},
  title   = {A mathematical theory of communication},
  year    = {1948},
  volume  = {27},
  number  = {3},
  pages   = {379-423},
  doi     = {10.1002/j.1538-7305.1948.tb01338.x}
}

@misc{https://doi.org/10.48550/arxiv.1409.0473,
  doi       = {10.48550/ARXIV.1409.0473},
  url       = {https://arxiv.org/abs/1409.0473},
  author    = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{rasmy2020medbert,
  title         = {Med-BERT: pre-trained contextualized embeddings on large-scale structured electronic health records for disease prediction},
  url           = {https://doi.org/10.48550/arXiv.2005.12833},
  author        = {Laila Rasmy and Yang Xiang and Ziqian Xie and Cui Tao and Degui Zhi},
  year          = {2020},
  eprint        = {2005.12833},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{pennington-etal-2014-glove,
  title     = {{G}lo{V}e: Global Vectors for Word Representation},
  author    = {Pennington, Jeffrey  and
               Socher, Richard  and
               Manning, Christopher},
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
  month     = oct,
  year      = {2014},
  address   = {Doha, Qatar},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D14-1162},
  doi       = {10.3115/v1/D14-1162},
  pages     = {1532--1543}
}

@article{10.1093/jamia/ocy178,
    author = {Yuan, Chi and Ryan, Patrick B and Ta, Casey and Guo, Yixuan and Li, Ziran and Hardin, Jill and Makadia, Rupa and Jin, Peng and Shang, Ning and Kang, Tian and Weng, Chunhua},
    title = "{Criteria2Query: a natural language interface to clinical databases for cohort definition}",
    journal = {Journal of the American Medical Informatics Association},
    volume = {26},
    number = {4},
    pages = {294-305},
    year = {2019},
    month = {02},
    issn = {1527-974X},
    doi = {10.1093/jamia/ocy178},
    url = {https://doi.org/10.1093/jamia/ocy178},
    eprint = {https://academic.oup.com/jamia/article-pdf/26/4/294/34151511/ocy178.pdf},
}

@misc{tseo2020information,
      title={Information Extraction of Clinical Trial Eligibility Criteria}, 
      author={Yitong Tseo and M. I. Salkola and Ahmed Mohamed and Anuj Kumar and Freddy Abnousi},
      year={2020},
      eprint={2006.07296},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Wissel2019ProspectiveVO,
  title={Prospective validation of a machine learning model that uses provider notes to identify candidates for resective epilepsy surgery},
  author={Benjamin D. Wissel and Hansel M Greiner and Tracy A. Glauser and Katherine D Holland-Bouley and Francesco T. Mangano and Daniel Santel and Robert Faist and Nanhua Zhang and John P. Pestian and Rhonda D. Szczesniak and Judith W. Dexheimer},
  journal={Epilepsia},
  year={2019},
  volume={61},
  pages={39 - 48}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}



